import torch
import torch.nn as nn
import torch.optim as optim
import torchaudio
import torchvision.models as models
from torch.utils.data import Dataset, DataLoader
import os
import pandas as pd
from sklearn.model_selection import train_test_split
import swanlab
import random
import numpy as np


# è®¾ç½®éšæœºç§å­
def set_seed(seed=42):
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def create_dataset_csv():
    # æ•°æ®é›†æ ¹ç›®å½•
    data_dir = "./audio_data"
    data = []

    # éå†æ‰€æœ‰å­ç›®å½•
    for label in os.listdir(data_dir):
        label_dir = os.path.join(data_dir, label)
        if os.path.isdir(label_dir):
            # éå†å­ç›®å½•ä¸­çš„æ‰€æœ‰wavæ–‡ä»¶
            for audio_file in os.listdir(label_dir):
                if audio_file.endswith(".wav"):
                    audio_path = os.path.join(label_dir, audio_file).replace("\\", "/")
                    data.append([audio_path, label])

    # åˆ›å»ºDataFrameå¹¶ä¿å­˜ä¸ºCSV
    df = pd.DataFrame(data, columns=["path", "label"])
    df.to_csv("audio_dataset.csv", index=False)
    return df


# è‡ªå®šä¹‰æ•°æ®é›†ç±»
class AudioDataset(Dataset):
    def __init__(self, df, resize, train_mode=True):
        self.audio_paths = df["path"].values
        # å°†æ ‡ç­¾è½¬æ¢ä¸ºæ•°å€¼
        self.label_to_idx = {
            label: idx for idx, label in enumerate(df["label"].unique())
        }
        self.labels = [self.label_to_idx[label] for label in df["label"].values]
        self.resize = resize
        self.train_mode = train_mode  # æ·»åŠ è®­ç»ƒæ¨¡å¼æ ‡å¿—

    def __len__(self):
        return len(self.audio_paths)

    def __getitem__(self, idx):
        # åŠ è½½éŸ³é¢‘æ–‡ä»¶
        waveform, sample_rate = torchaudio.load(self.audio_paths[idx])

        # å°†éŸ³é¢‘è½¬æ¢ä¸ºæ¢…å°”é¢‘è°±å›¾
        transform = torchaudio.transforms.MelSpectrogram(
            sample_rate=sample_rate, n_fft=4096, hop_length=1024, n_mels=32
        )
        mel_spectrogram = transform(waveform)

        # ä»…åœ¨è®­ç»ƒæ¨¡å¼ä¸‹è¿›è¡Œæ•°æ®å¢å¼º
        if self.train_mode:
            # 1. æ—¶é—´é®è”½ (Time Masking)ï¼šé€šè¿‡éšæœºé€‰æ‹©ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œç„¶åé®è”½æ‰20ä¸ªæ—¶é—´æ­¥
            time_mask = torchaudio.transforms.TimeMasking(time_mask_param=20)
            mel_spectrogram = time_mask(mel_spectrogram)

            # 2. é¢‘ç‡é®è”½ (Frequency Masking)ï¼šé€šè¿‡éšæœºé€‰æ‹©ä¸€ä¸ªé¢‘ç‡æ­¥ï¼Œç„¶åé®è”½æ‰20ä¸ªé¢‘ç‡æ­¥
            freq_mask = torchaudio.transforms.FrequencyMasking(freq_mask_param=20)
            mel_spectrogram = freq_mask(mel_spectrogram)

            # 3. éšæœºå¢åŠ é«˜æ–¯å™ªå£°
            if random.random() < 0.5:
                noise = torch.randn_like(mel_spectrogram) * 0.01
                mel_spectrogram = mel_spectrogram + noise
            # 4. éšæœºè°ƒæ•´å“åº¦
            if random.random() < 0.5:
                gain = random.uniform(0.8, 1.2)
                mel_spectrogram = mel_spectrogram * gain

        # ç¡®ä¿æ•°å€¼åœ¨åˆç†èŒƒå›´å†…
        mel_spectrogram = torch.clamp(mel_spectrogram, min=0)

        # è½¬æ¢ä¸º3é€šé“å›¾åƒæ ¼å¼ (ä¸ºäº†é€‚é…ResNet)
        mel_spectrogram = mel_spectrogram.repeat(3, 1, 1)

        # ç¡®ä¿å°ºå¯¸ä¸€è‡´
        resize = torch.nn.AdaptiveAvgPool2d((self.resize, self.resize))
        mel_spectrogram = resize(mel_spectrogram)

        return mel_spectrogram, self.labels[idx]


# ä¿®æ”¹ResNetæ¨¡å‹
class AudioClassifier(nn.Module):
    def __init__(self, num_classes):
        super(AudioClassifier, self).__init__()
        # åŠ è½½é¢„è®­ç»ƒçš„ResNet
        self.resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)
        # ä¿®æ”¹æœ€åçš„å…¨è¿æ¥å±‚
        self.resnet.fc = nn.Linear(512, num_classes)

    def forward(self, x):
        return self.resnet(x)


# è®­ç»ƒå‡½æ•°
def train_model(
    model,
    train_loader,
    val_loader,
    criterion,
    optimizer,
    scheduler,
    num_epochs,
    device,
    run,
):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        # å‰5ä¸ªepochè¿›è¡Œwarmup
        if epoch < 5:
            warmup_factor = (epoch + 1) / 5
            for param_group in optimizer.param_groups:
                param_group["lr"] = run.config.learning_rate * warmup_factor

        # optimizer.zero_grad()  # ç§»åˆ°å¾ªç¯å¤–éƒ¨

        for i, (inputs, labels) in enumerate(train_loader):
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()

            optimizer.step()
            optimizer.zero_grad()

            running_loss += loss.item()

            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        train_loss = running_loss
        train_acc = 100.0 * correct / total

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                val_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()

        val_loss = val_loss / len(val_loader)
        val_acc = 100.0 * correct / total

        # åªåœ¨warmupç»“æŸåä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨
        if epoch >= 5:
            scheduler.step()
        current_lr = scheduler.get_last_lr()[0]  # optimizer.param_groups[0]["lr"]

        # è®°å½•è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡
        swanlab.log(
            {
                "train/loss": train_loss,
                "train/acc": train_acc,
                "val/loss": val_loss,
                "val/acc": val_acc,
                "train/epoch": epoch,
                "train/lr": current_lr,
            }
        )

        print(f"Epoch {epoch + 1}:")
        print(f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%")
        print(f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
        print(f"Learning Rate: {current_lr:.6f}")

        torch.save(model.state_dict(), "audio_classifier.pth")


# ä¸»å‡½æ•°
def main():
    # è®¾ç½®éšæœºç§å­
    set_seed(42)

    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    run = swanlab.init(
        project="MarineSound",
        workspace="GenShinImpactMaster",
        experiment_name="ğŸ˜„resnext101_32x8d",
        config={
            "batch_size": 4,
            "learning_rate": 1e-4,
            "num_epochs": 30,
            "resize": 512,
            "weight_decay": 0,  # æ·»åŠ åˆ°é…ç½®ä¸­
        },
    )

    # ç”Ÿæˆæˆ–åŠ è½½æ•°æ®é›†CSVæ–‡ä»¶
    if not os.path.exists("audio_dataset.csv"):
        df = create_dataset_csv()
    else:
        df = pd.read_csv("audio_dataset.csv")

    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_df = pd.DataFrame()
    val_df = pd.DataFrame()

    for label in df["label"].unique():
        label_df = df[df["label"] == label]
        label_train, label_val = train_test_split(
            label_df, test_size=0.2, random_state=42
        )
        train_df = pd.concat([train_df, label_train])
        val_df = pd.concat([val_df, label_val])

    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    train_dataset = AudioDataset(train_df, resize=run.config.resize, train_mode=True)
    val_dataset = AudioDataset(val_df, resize=run.config.resize, train_mode=False)

    train_loader = DataLoader(
        train_dataset, batch_size=run.config.batch_size, shuffle=True
    )
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)

    # åˆ›å»ºæ¨¡å‹
    num_classes = len(df["label"].unique())  # æ ¹æ®å®é™…åˆ†ç±»æ•°é‡è®¾ç½®
    model = AudioClassifier(num_classes).to(device)

    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(
        model.parameters(),
        lr=run.config.learning_rate,
        weight_decay=run.config.weight_decay,
    )  # Adamä¼˜åŒ–å™¨

    # æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.StepLR(
        optimizer, step_size=10, gamma=0.1  # åœ¨ç¬¬10ä¸ªepochè¡°å‡  # è¡°å‡ç‡ä¸º0.1
    )

    # è®­ç»ƒæ¨¡å‹
    train_model(
        model,
        train_loader,
        val_loader,
        criterion,
        optimizer,
        scheduler,
        num_epochs=run.config.num_epochs,
        device=device,
        run=run,
    )


if __name__ == "__main__":
    main()
